# -*- coding: utf-8 -*-
"""2022dlcv_1_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HDmzZVOJXkq1Qi7RX3NMAogehZnzcy79
"""
# !gdown --id 1012Oi7Sp2aLSJK2QtH9QI8zFfcT7xTdz --output "./hw1_data.zip"
# !unzip -q "./hw1_data.zip" -d "./"
# !rm hw1_data.zip


import torch
import PIL
from PIL import Image
import matplotlib.pyplot as plt
import os
from torch.utils.data import DataLoader
import torchvision
from torchvision import models
import torch.nn as nn
import torchvision.transforms as T
import numpy as np

path_to_datafile = '/content/hw1_data'

class hw1_1_dataset:
    def __init__(self, filepath, transform_1, transform_2=None, data_type = 'train'):
        self.transform_1 = transform_1
        self.datapath = []
        self.transform_2 = transform_2
        self.data_type = data_type
        if data_type == 'train':
            for i in range(50):
                for j in range(450):
                    img_name = f'{i}_{j}.png'
                    temp_path = os.path.join(filepath, img_name)
                    self.datapath.append([temp_path, i])
        elif data_type == 'eval':
            for i in range(50):
                for j in range(450, 500):
                    img_name = f'{i}_{j}.png'
                    temp_path = os.path.join(filepath, img_name)
                    self.datapath.append([temp_path, i])
    
    def __len__(self):
        return len(self.datapath)
    
    def __getitem__(self, idx):
        [img_path, label] = self.datapath[idx]
        img = Image.open(img_path)
        if(self.data_type == 'train'):
            # print('jkkl')
            img_flip = T.RandomHorizontalFlip(1)(img)
            transformed_img = self.transform_1(img)
            img_flip = self.transform_1(img_flip)
            img.close()
            temp = []
            transformed_img = self.transform_2(transformed_img)
            img_flip = self.transform_2(img_flip)
            temp.append(transformed_img)
            temp.append(img_flip)
            return temp, int(label)
        else:
            transformed_img = self.transform_2(img)
            img.close()
        return transformed_img, int(label)

img_transform_1 = T.Compose([
    T.Resize(256),
    T.ColorJitter(brightness = 0.3, contrast = 0.3, saturation = 0.3, hue = 0.1), # good
    T.RandomRotation(5), # good
    T.RandomPerspective(p = 0.7),
])      
img_transform_2 = T.Compose([
    T.Resize(224),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406],
               std=[0.229, 0.224, 0.225])
])

p1_data_train = hw1_1_dataset(os.path.join(path_to_datafile, 'p1_data/train_50'), img_transform_1, img_transform_2, data_type='train')
p1_data_test = hw1_1_dataset(os.path.join(path_to_datafile, 'p1_data/val_50'), img_transform_1, img_transform_2, data_type='eval')
print(p1_data_train.__len__())
BATCH_SIZE = 64
EPOCH = 30

train_loader = DataLoader(p1_data_train, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(p1_data_test, batch_size=BATCH_SIZE, shuffle=False)

class hw1_model_1(nn.Module):
    def __init__(self):
        super().__init__()
        self.core = models.resnet50(weights='DEFAULT')
        # self.core = models.inception_v3(weights='DEFAULT')
        self.classifier = nn.Linear(1000, 50)
        
    def forward(self, x):
        x = self.core(x)
        x = self.classifier(x)
        return x

device = torch.device("cuda")
pretrained_model = hw1_model_1()
if(torch.cuda.is_available()):
    pretrained_model = pretrained_model.to(device)
else:
    print('WARNING!!!!!!!!!!!!!! MPS CAN\'T BE USED')
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(pretrained_model.parameters(), lr=0.00005)

from tqdm.notebook import tqdm
import math


for epoch in range(EPOCH):
    pretrained_model.train()
    corrects_all = 0
    all = 0
    print(epoch)
    progress = tqdm(total = math.ceil(22500/BATCH_SIZE))
    for batch_idx, (imgs, labels) in enumerate(train_loader):
        labels = labels.to(device)

        for i in range(len(imgs)):
            temp_img = imgs[i].to(device)
            optimizer.zero_grad()
            outputs = pretrained_model(temp_img)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            preds = torch.max(outputs, dim=1)[1]
            corrects = torch.sum(preds == labels).item()
            corrects_all += corrects
            all += BATCH_SIZE
        progress.update(1)
    print('acc: ', corrects_all/all)
    torch.save(pretrained_model.state_dict(), './first.ckpt')

    pretrained_model.eval()

    running_corrects = 0
    running_max_corrects = 0
    for batch_idx, (imgs, labels) in enumerate(test_loader):
        
        labels = labels.to(device)
        imgs = imgs.to(device)
        outputs = pretrained_model(imgs)
        preds = torch.max(outputs, dim=1)[1]
        corrects = torch.sum(preds == labels).item()
        running_corrects += corrects
    print("Test Acc:", running_corrects/(len(test_loader.dataset)))