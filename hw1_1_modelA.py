# -*- coding: utf-8 -*-
"""2022dlcv_1_1_raw.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ATmjqsIn3fDBF2bSP7CvuV5hbqT36PHs
"""

!nvidia-smi

!gdown --id 1012Oi7Sp2aLSJK2QtH9QI8zFfcT7xTdz --output "./hw1_data.zip"
!unzip -q "./hw1_data.zip" -d "./"
!rm hw1_data.zip

import torch
import PIL
from PIL import Image
import matplotlib.pyplot as plt
import os
from torch.utils.data import DataLoader
import torchvision
from torchvision import models
import torch.nn as nn
import torchvision.transforms as T
import numpy as np
# print(torch.backends.mps.is_available())

path_to_datafile = '/content/hw1_data'

# img=Image.open(os.path.join(path_to_datafile, 'p1_data/train_50/0_0.png'))
# plt.imshow(img)
# plt.show()

class hw1_1_dataset:
    def __init__(self, filepath, transform_1, transform_2=None, data_type = 'train'):
        self.transform_1 = transform_1
        self.datapath = []
        self.transform_2 = transform_2
        self.data_type = data_type
        if data_type == 'train':
            for i in range(50):
                for j in range(450):
                    img_name = f'{i}_{j}.png'
                    temp_path = os.path.join(filepath, img_name)
                    self.datapath.append([temp_path, i])
        elif data_type == 'eval':
            for i in range(50):
                for j in range(450, 500):
                    img_name = f'{i}_{j}.png'
                    temp_path = os.path.join(filepath, img_name)
                    self.datapath.append([temp_path, i])
    
    def __len__(self):
        return len(self.datapath)
    
    def __getitem__(self, idx):
        [img_path, label] = self.datapath[idx]
        img = Image.open(img_path)
        if(self.data_type == 'train'):
            # print('jkkl')
            img_flip = T.RandomHorizontalFlip(1)(img)
            transformed_img = self.transform_1(img)
            img_flip = self.transform_1(img_flip)
            img.close()
            temp = []
            # for i in range(len(transformed_img)):
            #     temp.append(self.transform_2(transformed_img[i]))
            transformed_img = self.transform_2(transformed_img)
            img_flip = self.transform_2(img_flip)
            temp.append(transformed_img)
            temp.append(img_flip)
            return temp, int(label)
        else:
            transformed_img = self.transform_2(img)
            img.close()
        return transformed_img, int(label)

# img_transform_1 = T.Compose([
#     T.RandomHorizontalFlip(),
#     T.RandomRotation(10)
# ])
img_transform_1 = T.Compose([
    T.Resize(256),
    # T.RandomHorizontalFlip(0.5), # good
    T.ColorJitter(brightness = 0.3, contrast = 0.3, saturation = 0.3, hue = 0.1), # good
    # T.RandomAdjustSharpness(2), # bad
    T.RandomRotation(5), # good
    T.RandomPerspective(p = 0.7),
    # T.GaussianBlur(5), # bad
    # T.RandomCrop(28)
    # T.TenCrop(24)
    # T.Grayscale(3)
])      
img_transform_2 = T.Compose([
    # T.RandomHorizontalFlip(0.5),
    T.Resize(224),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406],
               std=[0.229, 0.224, 0.225])
])

p1_data_train = hw1_1_dataset(os.path.join(path_to_datafile, 'p1_data/train_50'), img_transform_1, img_transform_2, data_type='train')
p1_data_test = hw1_1_dataset(os.path.join(path_to_datafile, 'p1_data/val_50'), img_transform_1, img_transform_2, data_type='eval')
print(p1_data_train.__len__())
BATCH_SIZE = 32
EPOCH = 100

train_loader = DataLoader(p1_data_train, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(p1_data_test, batch_size=BATCH_SIZE, shuffle=False)

# print(models.inception_v3())

class hw1_model_1(nn.Module):
    def __init__(self):
        super().__init__()
        self.core = models.resnet50()
        # self.core = models.inception_v3(weights='DEFAULT')
        self.classifier = nn.Linear(1000, 50)
        
    def forward(self, x):
        x = self.core(x)
        x = self.classifier(x)
        return x

device = torch.device("cuda")
# device = xm.xla_device()
raw_model = hw1_model_1()
ck = 18
raw_model.load_state_dict(torch.load('./drive/MyDrive/first_18.ckpt'))
# torch.save(raw_model.state_dict(), f'./first_{epoch+ck+1}.ckpt')
if(torch.cuda.is_available()):
    raw_model = raw_model.to(device)
else:
    print('WARNING!!!!!!!!!!!!!! MPS CAN\'T BE USED')
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(raw_model.parameters(), lr=0.00005)

from google.colab import drive
drive.mount('/content/drive')

from tqdm.notebook import tqdm
import math
best_epoch = 0
best = 0
for epoch in range(EPOCH):
    raw_model.train()
    corrects_all = 0
    all = 0
    print(epoch+ck+1)
    progress = tqdm(total = math.ceil(22500/BATCH_SIZE))
    for batch_idx, (imgs, labels) in enumerate(train_loader):
        labels = labels.to(device)

        for i in range(len(imgs)):
            temp_img = imgs[i].to(device)
            optimizer.zero_grad()
            outputs = raw_model(temp_img)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            preds = torch.max(outputs, dim=1)[1]
            corrects = torch.sum(preds == labels).item() 
            corrects_all += corrects
            all += BATCH_SIZE
        progress.update(1)
    print('acc: ', corrects_all/all)
    if(epoch == 0):
      torch.save(raw_model.state_dict(), './first_0.ckpt')
    

    raw_model.eval()

    running_corrects = 0
    running_max_corrects = 0
    for batch_idx, (imgs, labels) in enumerate(test_loader):
        
        labels = labels.to(device)
        imgs = imgs.to(device)
        outputs = raw_model(imgs)
        preds = torch.max(outputs, dim=1)[1]
        corrects = torch.sum(preds == labels).item()
        running_corrects += corrects
    test_acc = running_corrects/(len(test_loader.dataset))
    if test_acc > best:
        best = test_acc
        best_epoch = epoch
        torch.save(raw_model.state_dict(), f'./first_{epoch+ck+1}.ckpt')
    elif epoch - best_epoch > 5:
        break
    print("Test Acc:", test_acc)

import sklearn
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

def save_features(module, fin, fout):
    global class_features
    fs = torch.flatten(fout, 1)
    class_features.append(fs.detach().cpu().numpy())

# file_list = [file for file in os.listdir('./') if file.endswith('.ckpt')]
# file_a = math.floor(best_epoch/2)
# while file_a > 0:
#   if f'./first_{int(file_a)}.ckpt' in file_list:
#     file_a = int(file_a)
#     break
#   else:
#     file_a -= 1

model_list = ['/content/drive/MyDrive/first_0.ckpt', '/content/drive/MyDrive/first_18.ckpt', '/content/drive/MyDrive/first_37.ckpt']

for mod in model_list:
    raw_model.load_state_dict(torch.load(mod))
    raw_model.eval()
    class_features = []
    class_labels = []
    handler = raw_model.core.register_forward_hook(save_features)

    for imgs, labels in test_loader:
        imgs = imgs.to(device)
        labels = labels.to(device)
        _ = raw_model(imgs)
        class_labels.append(labels.detach().cpu().numpy())

    handler.remove()
    features = np.concatenate(class_features)
    # print(features)
    labels = np.concatenate(class_labels)

    pca = PCA(n_components=2)
    reduced = pca.fit_transform(features)
    # print(features.size())

    plt.figure(figsize=(16, 8))

    for i in range(50):
        selected = reduced[np.where(labels == i)[0]]
        plt.scatter(x=selected[:, 0], y=selected[:, 1], label=str(i))
    plt.tight_layout()
    plt.legend()

    tsne = TSNE(n_components=2, perplexity=50)
    reduced = tsne.fit_transform(features)

    plt.figure(figsize=(16, 8))

    for i in range(50):
        selected = reduced[np.where(labels == i)[0]]
        plt.scatter(selected[:, 0], selected[:, 1], label=str(i))
        
    plt.tight_layout()
    plt.legend()



"""## T-SNE visualization with labeled data"""

