# -*- coding: utf-8 -*-
"""2022dlcv_1_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aeFpHCJbw2bjpMUJ5-pDkUcoHPFF2oFp
"""

# !gdown --id 1012Oi7Sp2aLSJK2QtH9QI8zFfcT7xTdz --output "./hw1_data.zip"
# !unzip -q "./hw1_data.zip" -d "./"
# !rm hw1_data.zip

import torch
import PIL
from PIL import Image
import matplotlib.pyplot as plt
import os
from torch.utils.data import DataLoader
import torchvision
from torchvision import models
import torch.nn as nn
import torchvision.transforms as T
import numpy as np
import torch.nn.functional as F

path_to_datafile = '/content/hw1_data/p2_data'

"""### Tools"""

import scipy.misc
import imageio
import os

# source of read_masks and mean_iou_score: TA's code

def read_masks(filepath):
    '''
    Read masks from directory and tranform to categorical
    '''
    file_list = [file for file in os.listdir(filepath) if file.endswith('.png')]
    file_list.sort()
    n_masks = len(file_list)
    masks = np.empty((n_masks, 512, 512))

    for i, file in enumerate(file_list):
        mask = imageio.imread(os.path.join(filepath, file))
        mask = (mask >= 128).astype(int)
        mask = 4 * mask[:, :, 0] + 2 * mask[:, :, 1] + mask[:, :, 2]
        masks[i, mask == 3] = 0  # (Cyan: 011) Urban land 
        masks[i, mask == 6] = 1  # (Yellow: 110) Agriculture land 
        masks[i, mask == 5] = 2  # (Purple: 101) Rangeland 
        masks[i, mask == 2] = 3  # (Green: 010) Forest land 
        masks[i, mask == 1] = 4  # (Blue: 001) Water 
        masks[i, mask == 7] = 5  # (White: 111) Barren land 
        masks[i, mask == 0] = 6  # (Black: 000) Unknown 

    return masks

def mean_iou_score(pred, labels):
    '''
    Compute mean IoU score over 6 classes
    '''
    mean_iou = 0
    for i in range(6):
        tp_fp = np.sum(pred == i)
        tp_fn = np.sum(labels == i)
        tp = np.sum((pred == i) * (labels == i))
        iou = tp / (tp_fp + tp_fn - tp + 1e-7)
        mean_iou += iou / 6
        # print('class #%d : %1.5f'%(i, iou))
    # print('\nmean_iou: %f\n' % mean_iou)

    return mean_iou

"""# Data"""

import random
class hw1_1_dataset:
    def __init__(self, filepath, transform, train):
        self.transform = transform
        self.train = train
        self.filepath = filepath
        self.masks = torch.from_numpy(np.int64(read_masks(filepath)))
        self.data_list = [file for file in os.listdir(filepath) if file.endswith('.jpg')]
        self.data_list.sort()
        n_data = len(self.data_list)
        if(n_data != self.masks.shape[0]):
            print('data do not match')
    
    def __len__(self):
        return len(self.data_list)
    
    def __getitem__(self, idx):
        img_path = self.data_list[idx]
        img = Image.open(os.path.join(self.filepath, img_path))
        label = self.masks[idx]
        if self.train :
          random_flip = [0, 1]
          random_rotate = [0, 90, 180, 270]
          flip = random.sample(random_flip, 1)[0]
          rotate = random.sample(random_rotate, 1)[0]
          if random_flip:
            img = T.functional.hflip(img)
          img = T.functional.rotate(img, angle = rotate)
          if random_flip:
            label = T.functional.hflip(label)
          label = T.functional.rotate(torch.unsqueeze(label, 0), angle = rotate).squeeze()
        # img = T.Compose([
        #     T.RandomAutocontrast(p = 1),
        #     T.RandomAdjustSharpness(2, p = 1)
        # ])(img)
        transformed_img = self.transform(img)
        return (transformed_img, label)

img_transform_1 = T.Compose([
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406],
               std=[0.229, 0.224, 0.225])
])

p2_data_train = hw1_1_dataset(os.path.join(path_to_datafile, 'train'), img_transform_1, train = True)
p2_data_test = hw1_1_dataset(os.path.join(path_to_datafile, 'validation'), img_transform_1, train = False)

BATCH_SIZE = 6
train_loader = DataLoader(p2_data_train, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(p2_data_test, batch_size=BATCH_SIZE, shuffle=False)

"""### Model"""

"""##### DV3
source: https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/"""

class DLV3(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""

    def __init__(self):
        super().__init__()
        self.dlv3 = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)
        self.classifier = nn.Conv2d(21, 7, kernel_size = 1)
    def forward(self, x):
        out = self.dlv3(x)['out']
        out = self.classifier(out)
        return out

device = torch.device("cuda")
pretrained_model = DLV3()
# ck = 75
# pretrained_model.load_state_dict(torch.load(f'/content/drive/MyDrive/DV3_R{ck}.ckpt'))
if(torch.cuda.is_available()):
    pretrained_model = pretrained_model.to(device)
else:
    print('WARNING!!!!!!!!!!!!!! MPS CAN\'T BE USED')
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(pretrained_model.parameters(), lr=0.00001)

"""### Train"""

from tqdm.notebook import tqdm
import math

EPOCH = 90
so_far_best = 0
for epoch in range(EPOCH):
    pretrained_model.train()
    corrects = 0
    print(epoch+ck+1)
    progress = tqdm(total = math.ceil(len(p2_data_train)/BATCH_SIZE))
    for batch_idx, (imgs, labels) in enumerate(train_loader):
        labels = labels.to(device)
        temp_img = imgs.to(device)
        optimizer.zero_grad()
        outputs = pretrained_model(temp_img)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        preds = torch.max(outputs, dim=1)[1]
        corrects += torch.sum(preds == labels).item()
        progress.update(1)
    print('Correct rate: ', corrects/(512*512*2000))
    
    pretrained_model.eval()
    tp = [0,0,0,0,0,0]
    assembly = [0,0,0,0,0,0]
    for batch_idx, (imgs, labels) in enumerate(test_loader):
        
        labels = labels.to(device)
        imgs = imgs.to(device)
        outputs = pretrained_model(imgs)
        preds = torch.max(outputs, dim=1)[1]
        for i in range(6):
          tp[i] += torch.sum((preds == i)*(labels == i)).item()
          assembly[i] += (torch.sum(preds == i).item() + torch.sum(labels == i).item())
    mean_iou = 0
    # 55 63 68 *75 **76 ***88
    for i in range(6):
      mean_iou += (tp[i]/(assembly[i]-tp[i]))/6
    print(mean_iou)
    if(so_far_best < mean_iou or mean_iou > 0.73):
      so_far_best = mean_iou
      torch.save(pretrained_model.state_dict(), f'/content/drive/MyDrive/DV3_R{epoch+ck+1}.ckpt')